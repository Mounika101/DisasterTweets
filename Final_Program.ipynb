{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29xBVw-cFNcO",
        "outputId": "e59337e3-3371-4dac-b521-afa681795679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqDN6UH8FSyX",
        "outputId": "736baa48-0961-4a99-8056-6ec1a91af0b8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Conv1D, LSTM, Dense, GlobalMaxPooling1D"
      ],
      "metadata": {
        "id": "lLzc-M9nFhZs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('dataset1.csv')\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU0ivjmSFxIa",
        "outputId": "8a50f8c3-4df6-4554-987b-7ae9a40e7a89"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          id                                               text  target\n",
            "0          0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n",
            "1          1  Telangana: Section 144 has been imposed in Bha...       1\n",
            "2          2  Arsonist sets cars ablaze at dealership https:...       1\n",
            "3          3  Arsonist sets cars ablaze at dealership https:...       1\n",
            "4          4  \"Lord Jesus, your love brings freedom and pard...       0\n",
            "...      ...                                                ...     ...\n",
            "11365  11365  Media should have warned us well in advance. T...       0\n",
            "11366  11366  i feel directly attacked ðŸ’€ i consider moonb...       0\n",
            "11367  11367  i feel directly attacked ðŸ’€ i consider moonb...       0\n",
            "11368  11368  ok who remember \"outcast\" nd the \"dora\" au?? T...       0\n",
            "11369  11369     Jake Corway wrecked while running 14th at IRP.       1\n",
            "\n",
            "[11370 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['text'] = data['text'].str.replace('[^\\w\\s]','') \n",
        "data['text'] = data['text'].str.replace('\\d+','')  \n",
        "data['text'] = data['text'].str.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os61c9grF11p",
        "outputId": "0e4cb92d-2c8b-4304-b17c-cd4d7e91cf1d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-6be140546912>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['text'] = data['text'].str.replace('[^\\w\\s]','')\n",
            "<ipython-input-67-6be140546912>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  data['text'] = data['text'].str.replace('\\d+','')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n"
      ],
      "metadata": {
        "id": "EfNlx_f6F7Zp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data:\")\n",
        "print(train_data)\n",
        "\n",
        "print(\"Testing Data:\")\n",
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk6hC9_EOWUi",
        "outputId": "5be9cfbf-3cab-4f6e-e84c-86b4481b2cc9"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "          id                                               text  target\n",
            "9313    9313  Theres a wonderful  photo view of the inside o...       0\n",
            "8369    8369  The warned everybody FOUR years ago about this...       0\n",
            "2762    2762  Hello Eric  A social media serye where Lola Ca...       0\n",
            "1683    1683  How many burning buildings have you run into t...       0\n",
            "2487    2487  Sgt David Edward Lloyd One of THE FEW httpstco...       0\n",
            "...      ...                                                ...     ...\n",
            "11284  11284  After causing the wreck theyre like httpstcokZ...       0\n",
            "5191    5191  Letâs get the Starboy to k subscribers Before ...       0\n",
            "5390    5390  Been a long day of storm surveys and one of ou...       0\n",
            "860      860  As we work on the next one this was what leadi...       0\n",
            "7270    7270  Im not supporting the colony narrative but it ...       0\n",
            "\n",
            "[10233 rows x 3 columns]\n",
            "Testing Data:\n",
            "          id                                               text  target\n",
            "3495    3495  How many illegal buildings should be demolishe...       0\n",
            "5461    5461                         Whoâs fatality is this tho       0\n",
            "9794    9794  OnThisDay  Chinese state media confirmed that ...       1\n",
            "11105  11105  With any luck you will miss the windstorm on e...       0\n",
            "1803    1803  Inferno on Black Friday   deaths  buildings to...       1\n",
            "...      ...                                                ...     ...\n",
            "2087    2087  adap successful shorting is hard way beyond my...       0\n",
            "3          3  Arsonist sets cars ablaze at dealership httpst...       1\n",
            "4110    4110  I know its all about Taal and Pinatubo pero Mt...       1\n",
            "1785    1785  Displaced home and business owners Shut down t...       1\n",
            "6128    6128  I want company to go to these places and eat t...       0\n",
            "\n",
            "[1137 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "m3-5AZioF_Od"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMUjTPADGC-F",
        "outputId": "c2862512-e89c-455b-b7b3-6a8c3cba7074"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "adplwCqMGHIN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bert_encode(texts, tokenizer, max_len=512):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded = tokenizer.encode_plus(\n",
        "            text, \n",
        "            add_special_tokens=True,\n",
        "            max_length=max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids.append(encoded['input_ids'])\n",
        "        attention_masks.append(encoded['attention_mask'])\n",
        "    \n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "    \n",
        "    return input_ids, attention_masks\n",
        "    \n",
        "train_input_ids, train_attention_masks = bert_encode(train_data['text'].values, tokenizer)\n",
        "test_input_ids, test_attention_masks = bert_encode(test_data['text'].values, tokenizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O6EEoLkGK8y",
        "outputId": "dd9f16e3-a226-429f-de38-bf494b07ab85"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=tokenizer.vocab_size, output_dim=100, input_length=1024))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "model.add(LSTM(units=64, return_sequences=True))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "YyHxdqEeGNgT"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0Ax_nk1cGXWr"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "Tgawp_9HGaDE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "train_input_ids_tf = tf.convert_to_tensor(train_input_ids.numpy())\n",
        "train_attention_masks_tf = tf.convert_to_tensor(train_attention_masks.numpy())\n",
        "\n",
        "concat_layer = Concatenate()([train_input_ids_tf, train_attention_masks_tf])\n"
      ],
      "metadata": {
        "id": "yuP9yD-EGcgZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    concat_layer.numpy(),\n",
        "    train_data['target'].values,\n",
        "    epochs=5,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVBBQUD0Gfgk",
        "outputId": "761b3edb-cd04-49ea-ab85-39007938660f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "320/320 [==============================] - 285s 879ms/step - loss: 0.4051 - accuracy: 0.8369\n",
            "Epoch 2/5\n",
            "320/320 [==============================] - 281s 879ms/step - loss: 0.2179 - accuracy: 0.9248\n",
            "Epoch 3/5\n",
            "320/320 [==============================] - 282s 882ms/step - loss: 0.1291 - accuracy: 0.9604\n",
            "Epoch 4/5\n",
            "320/320 [==============================] - 280s 874ms/step - loss: 0.0769 - accuracy: 0.9780\n",
            "Epoch 5/5\n",
            "320/320 [==============================] - 282s 881ms/step - loss: 0.0505 - accuracy: 0.9871\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f542589d360>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_ids_tf = tf.convert_to_tensor(test_input_ids.numpy())\n",
        "test_attention_masks_tf = tf.convert_to_tensor(test_attention_masks.numpy())\n",
        "\n",
        "concat_layer = Concatenate()([test_input_ids_tf, test_attention_masks_tf])\n",
        "test_pred = model.predict(concat_layer.numpy())\n",
        "test_pred = np.round(test_pred).flatten()\n",
        "test_true = test_data['target'].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx72zhfIGlPU",
        "outputId": "7397dacf-bbce-417a-e632-ebccb72c92dc"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36/36 [==============================] - 6s 153ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = accuracy_score(test_true, test_pred)\n",
        "precision = precision_score(test_true, test_pred)\n",
        "recall = recall_score(test_true, test_pred)\n",
        "f1 = f1_score(test_true, test_pred)"
      ],
      "metadata": {
        "id": "4472QjDLNDvZ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 Score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tw4cJNrNIx2",
        "outputId": "f2d73980-ad0d-4f55-8a28-91a1711b098c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9023746701846965\n",
            "Precision: 0.75625\n",
            "Recall: 0.6269430051813472\n",
            "F1 Score: 0.6855524079320112\n"
          ]
        }
      ]
    }
  ]
}